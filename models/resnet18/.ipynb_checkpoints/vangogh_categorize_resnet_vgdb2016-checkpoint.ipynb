{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "Rm3R18a3skbb",
    "outputId": "31fdeab3-6368-46a7-a762-e559f7227970"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "AuAzjfgx5Zxz",
    "outputId": "6996d576-96d1-42d6-f6c2-be15ca94952e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uninstalling Pillow-5.4.1:\n",
      "  Would remove:\n",
      "    /usr/local/lib/python3.6/dist-packages/PIL/*\n",
      "    /usr/local/lib/python3.6/dist-packages/Pillow-5.4.1.dist-info/*\n",
      "Proceed (y/n)? y\n",
      "  Successfully uninstalled Pillow-5.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall Pillow  #if the error with PIL appears when running training code, repeat this step and the installation step below to fix it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "O9SJ1gq6804t",
    "outputId": "89ac982d-6b8b-4419-a318-00d9f707b8f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Pillow==4.0.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/e8/b3fbf87b0188d22246678f8cd61e23e31caa1769ebc06f1664e2e5fe8a17/Pillow-4.0.0-cp36-cp36m-manylinux1_x86_64.whl (5.6MB)\n",
      "\u001b[K    100% |████████████████████████████████| 5.6MB 5.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow==4.0.0) (0.46)\n",
      "\u001b[31mtorchvision 0.2.1 has requirement pillow>=4.1.1, but you'll have pillow 4.0.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: Pillow\n",
      "Successfully installed Pillow-4.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install Pillow==4.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "MWeznELsGK0v",
    "outputId": "69bc3b17-04b0-47d4-f5f0-2aa5221ffe22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Pillow\n",
      "Version: 4.0.0\n",
      "Summary: Python Imaging Library (Fork)\n",
      "Home-page: http://python-pillow.org\n",
      "Author: Alex Clark (Fork Author)\n",
      "Author-email: aclark@aclark.net\n",
      "License: Standard PIL License\n",
      "Location: /usr/local/lib/python3.6/dist-packages\n",
      "Requires: olefile\n",
      "Required-by: tflearn, magenta\n"
     ]
    }
   ],
   "source": [
    "!pip show pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8hpKgUa2GOq5"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "def register_extension(id, extension): Image.EXTENSION[extension.lower()] = id.upper()\n",
    "Image.register_extension = register_extension\n",
    "def register_extensions(id, extensions): \n",
    "  for extension in extensions: register_extension(id, extension)\n",
    "Image.register_extensions = register_extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lH__IBEJuOCU",
    "outputId": "9fc72eae-79a4-4129-fa7d-bb4bd7da8bf3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/pytorch_challenge_showcase\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/My Drive/pytorch_challenge_showcase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x6VUV8nHmadf"
   },
   "source": [
    "# New Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "8a-t1bW5uPpn",
    "outputId": "89ab413a-0a2a-4222-9848-e40f72cfc4b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-01-07 15:31:22--  https://s3-eu-west-1.amazonaws.com/pfigshare-u-files/5870145/vgdb_2016.zip\n",
      "Resolving s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)... 52.218.105.66\n",
      "Connecting to s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)|52.218.105.66|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5707509034 (5.3G) [binary/octet-stream]\n",
      "Saving to: ‘vgdb_2016.zip’\n",
      "\n",
      "vgdb_2016.zip       100%[===================>]   5.32G  41.7MB/s    in 2m 16s  \n",
      "\n",
      "2019-01-07 15:33:38 (40.0 MB/s) - ‘vgdb_2016.zip’ saved [5707509034/5707509034]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download the dataset and unzip\n",
    "!wget https://s3-eu-west-1.amazonaws.com/pfigshare-u-files/5870145/vgdb_2016.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 5882
    },
    "colab_type": "code",
    "id": "2VUrUHENwT1B",
    "outputId": "53544867-513b-4b0b-a448-afad9b9b00e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  vgdb_2016.zip\n",
      "   creating: vgdb_2016/\n",
      "   creating: vgdb_2016/test/\n",
      "   creating: vgdb_2016/test/vg/\n",
      "  inflating: vgdb_2016/test/vg/vg_9100648.png  \n",
      "  inflating: vgdb_2016/test/vg/vg_9378884.png  \n",
      "  inflating: vgdb_2016/test/vg/vg_9516223.png  \n",
      "  inflating: vgdb_2016/test/vg/vg_9387502.png  \n",
      "  inflating: vgdb_2016/test/vg/vg_9463012.png  \n",
      "  inflating: vgdb_2016/test/vg/vg_9413420.png  \n",
      "  inflating: vgdb_2016/test/vg/vg_9421984.png  \n",
      "  inflating: vgdb_2016/test/vg/vg_17177301.png  \n",
      "  inflating: vgdb_2016/test/vg/vg_9436384.png  \n",
      "  inflating: vgdb_2016/test/vg/vg_9494947.png  \n",
      "  inflating: vgdb_2016/test/vg/vg_9414279.png  \n",
      "  inflating: vgdb_2016/test/vg/vg_151874.png  \n",
      "  inflating: vgdb_2016/test/vg/vg_9103139.png  \n",
      "  inflating: vgdb_2016/test/vg/vg_9106795.png  \n",
      "  inflating: vgdb_2016/test/vg/vg_9281980.png  \n",
      "  inflating: vgdb_2016/test/vg/vg_9427795.png  \n",
      "  inflating: vgdb_2016/test/vg/vg_9110201.png  \n",
      "  inflating: vgdb_2016/test/vg/vg_9386980.png  \n",
      "  inflating: vgdb_2016/test/vg/vg_9443864.png  \n",
      "  inflating: vgdb_2016/test/vg/vg_9471412.png  \n",
      "  inflating: vgdb_2016/test/vg/vg_9514157.png  \n",
      "  inflating: vgdb_2016/test/vg/vg_22263227.png  \n",
      "  inflating: vgdb_2016/test/vg/vg_9463608.png  \n",
      "  inflating: vgdb_2016/test/vg/vg_9506505.png  \n",
      "  inflating: vgdb_2016/test/vg/vg_33566806.png  \n",
      "   creating: vgdb_2016/test/nvg/\n",
      "  inflating: vgdb_2016/test/nvg/nvg_21997189.png  \n",
      "  inflating: vgdb_2016/test/nvg/nvg_32709917.png  \n",
      "  inflating: vgdb_2016/test/nvg/nvg_23768590.png  \n",
      "  inflating: vgdb_2016/test/nvg/nvg_18581296.png  \n",
      "  inflating: vgdb_2016/test/nvg/nvg_14943497.png  \n",
      "  inflating: vgdb_2016/test/nvg/nvg_37306601.png  \n",
      "  inflating: vgdb_2016/test/nvg/nvg_37662889.png  \n",
      "  inflating: vgdb_2016/test/nvg/nvg_22051210.png  \n",
      "  inflating: vgdb_2016/test/nvg/nvg_10582548.png  \n",
      "  inflating: vgdb_2016/test/nvg/nvg_10658644.png  \n",
      "  inflating: vgdb_2016/test/nvg/nvg_9780042.png  \n",
      "  inflating: vgdb_2016/test/nvg/nvg_18935581.png  \n",
      "  inflating: vgdb_2016/test/nvg/nvg_23900199.png  \n",
      "  inflating: vgdb_2016/test/nvg/nvg_27065927.png  \n",
      "  inflating: vgdb_2016/test/nvg/nvg_26188226.png  \n",
      "  inflating: vgdb_2016/test/nvg/nvg_24436341.png  \n",
      "  inflating: vgdb_2016/test/nvg/nvg_26635422.png  \n",
      "  inflating: vgdb_2016/test/nvg/nvg_22493218.png  \n",
      "  inflating: vgdb_2016/test/nvg/nvg_22189100.png  \n",
      "  inflating: vgdb_2016/test/nvg/nvg_22126474.png  \n",
      "  inflating: vgdb_2016/test/nvg/nvg_24782382.png  \n",
      "  inflating: vgdb_2016/test/nvg/nvg_21880515.png  \n",
      "  inflating: vgdb_2016/test/nvg/nvg_23820938.png  \n",
      "  inflating: vgdb_2016/test/nvg/nvg_16022414.png  \n",
      "  inflating: vgdb_2016/test/nvg/nvg_25164508.png  \n",
      "  inflating: vgdb_2016/test/nvg/nvg_22784729.png  \n",
      "  inflating: vgdb_2016/test/nvg/nvg_15057402.png  \n",
      "  inflating: vgdb_2016/test/nvg/nvg_19287801.png  \n",
      "  inflating: vgdb_2016/test/nvg/nvg_22140276.png  \n",
      "  inflating: vgdb_2016/test/nvg/nvg_6860814.png  \n",
      "  inflating: vgdb_2016/test/nvg/nvg_8379845.png  \n",
      "  inflating: vgdb_2016/test/nvg/nvg_35997635.png  \n",
      "  inflating: vgdb_2016/test/nvg/nvg_10500055.png  \n",
      "  inflating: vgdb_2016/test/nvg/nvg_19212119.png  \n",
      "  inflating: vgdb_2016/test/nvg/nvg_10715961.png  \n",
      "  inflating: vgdb_2016/test/nvg/nvg_25057402.png  \n",
      "  inflating: vgdb_2016/test/nvg/nvg_30592536.png  \n",
      "  inflating: vgdb_2016/test/nvg/nvg_17372314.png  \n",
      "  inflating: vgdb_2016/test/nvg/nvg_22007517.png  \n",
      "  inflating: vgdb_2016/test/nvg/nvg_12205276.png  \n",
      "  inflating: vgdb_2016/test/nvg/nvg_27063925.png  \n",
      "  inflating: vgdb_2016/test/nvg/nvg_18195595.png  \n",
      "   creating: vgdb_2016/train/\n",
      "   creating: vgdb_2016/train/vg/\n",
      "  inflating: vgdb_2016/train/vg/vg_9370435.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9478303.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9371718.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9428285.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_15415578.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_21880626.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_6491390.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9403031.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9394799.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9451652.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9420363.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9436306.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_2702957.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9107153.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9414081.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9402635.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_35997386.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_24041019.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_35168556.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9362665.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9484726.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9478847.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9478597.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9100630.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9436349.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9386580.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9428218.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_17996029.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9502285.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9141315.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9395208.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9453890.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9502392.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9521781.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9361739.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9427672.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9453821.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9362687.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9420622.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_27834755.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9403242.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9395122.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9485706.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9502466.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9427896.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_7058518.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9515739.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9103208.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9487154.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_21987773.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9403372.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_32403813.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9421829.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9394743.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9516321.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9428381.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_7276652.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9387451.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_6918481.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9108744.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_3065379.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9484311.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_21880258.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_26873520.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9402657.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9367533.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9395004.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9478276.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9379187.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9371066.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9372026.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_38300740.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9363025.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_17177561.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9420429.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_33566148.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9386622.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9413528.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9427299.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9386855.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9436454.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9107260.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_809945.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9428313.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9413641.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9428303.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9420385.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9387711.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9402859.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_21880259.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9522011.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9436481.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9428263.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9106908.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9421071.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9420564.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_34854099.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9413935.png  \n",
      "  inflating: vgdb_2016/train/vg/vg_9516813.png  \n",
      "   creating: vgdb_2016/train/nvg/\n",
      "  inflating: vgdb_2016/train/nvg/nvg_21906981.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_1869973.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_22007567.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_21997191.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_10770177.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_22009453.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_24814864.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_23569262.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_31638649.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_23993287.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_17713396.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_33826989.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_16127743.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_38390449.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_36812939.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_31699808.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_23568864.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_22141186.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_7284207.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_17354356.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_11884559.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_21908649.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_35513489.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_23569201.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_22490586.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_6371178.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_36442012.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_28595835.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_31339154.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_18555269.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_21993962.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_24816634.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_19108352.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_37263995.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_29971535.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_37871088.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_17478904.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_22490610.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_149071.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_6363880.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_21730756.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_23821678.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_18824494.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_31699635.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_21880237.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_36063197.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_21906492.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_36442167.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_19106724.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_1595836.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_27066013.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_20756232.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_24819441.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_22009499.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_19072936.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_10308515.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_19072754.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_21543045.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_27348022.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_16168218.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_22141790.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_36063145.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_21997150.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_24983432.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_21898438.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_23881908.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_21897497.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_25475565.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_19287819.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_21854016.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_36441793.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_23771315.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_10509718.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_22784704.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_37649554.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_22337555.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_21996873.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_10783832.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_18982353.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_29657338.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_24815605.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_21977349.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_17361848.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_28925363.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_17624166.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_24803553.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_36442235.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_31699760.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_35513713.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_17474017.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_10577408.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_17661393.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_14943679.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_24601995.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_23597199.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_30871570.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_17354151.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_26854633.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_9639794.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_30872127.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_18528781.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_23592980.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_22636123.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_17473975.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_21996773.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_11806172.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_8977210.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_28926056.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_19106540.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_17474430.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_31699776.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_18345871.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_21856131.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_9059012.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_21983755.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_29422787.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_33285874.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_20250383.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_21908713.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_20892502.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_8332724.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_23609262.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_23768667.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_17885266.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_7867410.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_22490554.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_21911864.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_24637182.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_26110321.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_24817530.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_29518448.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_25247359.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_2606381.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_15451333.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_21880277.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_20867663.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_21732069.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_23501598.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_22267023.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_11595528.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_19212307.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_22764884.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_36761870.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_23597297.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_19331132.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_30496862.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_35513255.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_19319841.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_10716788.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_18649551.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_7195974.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_26801435.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_8947760.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_17885332.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_33286072.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_8040213.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_21240118.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_18008573.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_20009450.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_23775847.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_21996858.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_18581184.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_23993076.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_10695501.png  \n",
      "  inflating: vgdb_2016/train/nvg/nvg_21880248.png  \n",
      "  inflating: vgdb_2016/vgdb_2016.csv  \n",
      "   creating: vgdb_2016/check/\n",
      "  inflating: vgdb_2016/check/9414428.png  \n",
      "  inflating: vgdb_2016/check/9420113.png  \n",
      "  inflating: vgdb_2016/readme.txt    \n",
      "  inflating: vgdb_2016/license.txt   \n"
     ]
    }
   ],
   "source": [
    "!unzip \"vgdb_2016.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "tiZSsZDPvBeH",
    "outputId": "3e869688-e803-4d7c-c2ee-331f04f723ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tcmalloc: large alloc 1073750016 bytes == 0x5888c000 @  0x7fdcd37bc2a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n"
     ]
    }
   ],
   "source": [
    "# http://pytorch.org/\n",
    "from os.path import exists\n",
    "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
    "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
    "\n",
    "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lE6-XKc8yFPK",
    "outputId": "3020c4ab-c8e9-4e5b-cbe9-ff7a855d0962"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!  Training on GPU ...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# check if CUDA is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cBlOm02lrvto"
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "LCDflHJGrxk6",
    "outputId": "c8dab5ec-bf82-4e34-881e-67ca211bcb1d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.torch/models/resnet18-5c106cde.pth\n",
      "100%|██████████| 46827520/46827520 [00:00<00:00, 67597034.47it/s]\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "for param in model.parameters():\n",
    "  param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1445
    },
    "colab_type": "code",
    "id": "dQ2dZMsPsLBc",
    "outputId": "a2629093-8411-415c-afdb-6b215d7db48d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HPfdpulQ3fUq"
   },
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aC_lFkH73ov3"
   },
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(512, 2, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "avyMIVS1sRkk"
   },
   "outputs": [],
   "source": [
    "# convert data to a normalized torch.FloatTensor\n",
    "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
    "                                       transforms.RandomResizedCrop(224),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                            [0.229, 0.224, 0.225])])\n",
    "\n",
    "valid_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                           [0.229, 0.224, 0.225])])\n",
    "\n",
    "data_dir = \"vgdb_2016\"\n",
    "\n",
    "train_data = datasets.ImageFolder(data_dir+\"/train\", transform=train_transforms)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "\n",
    "valid_data = datasets.ImageFolder(data_dir+\"/test\", transform=valid_transforms)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UAsnC5g25WdL"
   },
   "outputs": [],
   "source": [
    "if train_on_gpu:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RT5FTK8P5sxj",
    "outputId": "5ebb174f-5369-433b-85e2-1da5952c717d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vg', 'nvg']\n"
     ]
    }
   ],
   "source": [
    "# criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# specify the image classes\n",
    "classes = ['vg','nvg']\n",
    "\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 853
    },
    "colab_type": "code",
    "id": "PE3cpfPByMpQ",
    "outputId": "60ae46c1-385e-43c3-c071-40dde1831ff9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:2274: DecompressionBombWarning: Image size (178946307 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  :returns: Returns a flipped or rotated copy of this image.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.654623 \tValidation Loss: 0.617449\n",
      "Validation loss decreased (inf --> 0.617449).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 0.549895 \tValidation Loss: 0.565010\n",
      "Validation loss decreased (0.617449 --> 0.565010).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 0.519337 \tValidation Loss: 0.521159\n",
      "Validation loss decreased (0.565010 --> 0.521159).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 0.483343 \tValidation Loss: 0.501072\n",
      "Validation loss decreased (0.521159 --> 0.501072).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 0.451743 \tValidation Loss: 0.455877\n",
      "Validation loss decreased (0.501072 --> 0.455877).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 0.406066 \tValidation Loss: 0.426445\n",
      "Validation loss decreased (0.455877 --> 0.426445).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 0.413242 \tValidation Loss: 0.411532\n",
      "Validation loss decreased (0.426445 --> 0.411532).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 0.354819 \tValidation Loss: 0.392446\n",
      "Validation loss decreased (0.411532 --> 0.392446).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 0.347259 \tValidation Loss: 0.389961\n",
      "Validation loss decreased (0.392446 --> 0.389961).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.366747 \tValidation Loss: 0.360690\n",
      "Validation loss decreased (0.389961 --> 0.360690).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.354366 \tValidation Loss: 0.366094\n",
      "Epoch: 12 \tTraining Loss: 0.329329 \tValidation Loss: 0.369973\n",
      "Epoch: 13 \tTraining Loss: 0.378517 \tValidation Loss: 0.350500\n",
      "Validation loss decreased (0.360690 --> 0.350500).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.359603 \tValidation Loss: 0.358668\n",
      "Epoch: 15 \tTraining Loss: 0.350473 \tValidation Loss: 0.335456\n",
      "Validation loss decreased (0.350500 --> 0.335456).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.346116 \tValidation Loss: 0.340039\n",
      "Epoch: 17 \tTraining Loss: 0.327319 \tValidation Loss: 0.334603\n",
      "Validation loss decreased (0.335456 --> 0.334603).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.309099 \tValidation Loss: 0.347462\n",
      "Epoch: 19 \tTraining Loss: 0.303845 \tValidation Loss: 0.331325\n",
      "Validation loss decreased (0.334603 --> 0.331325).  Saving model ...\n",
      "Epoch: 20 \tTraining Loss: 0.291033 \tValidation Loss: 0.366784\n",
      "Epoch: 21 \tTraining Loss: 0.289041 \tValidation Loss: 0.343894\n",
      "Epoch: 22 \tTraining Loss: 0.335483 \tValidation Loss: 0.342841\n",
      "Epoch: 23 \tTraining Loss: 0.300656 \tValidation Loss: 0.333063\n",
      "Epoch: 24 \tTraining Loss: 0.291828 \tValidation Loss: 0.331487\n",
      "Epoch: 25 \tTraining Loss: 0.277271 \tValidation Loss: 0.355375\n",
      "Epoch: 26 \tTraining Loss: 0.311128 \tValidation Loss: 0.326387\n",
      "Validation loss decreased (0.331325 --> 0.326387).  Saving model ...\n",
      "Epoch: 27 \tTraining Loss: 0.254421 \tValidation Loss: 0.318065\n",
      "Validation loss decreased (0.326387 --> 0.318065).  Saving model ...\n",
      "Epoch: 28 \tTraining Loss: 0.290995 \tValidation Loss: 0.332407\n",
      "Epoch: 29 \tTraining Loss: 0.280125 \tValidation Loss: 0.333447\n",
      "Epoch: 30 \tTraining Loss: 0.287511 \tValidation Loss: 0.349450\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 30\n",
    "\n",
    "valid_loss_min = np.Inf # track change in validation loss\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "\n",
    "    # keep track of training and validation loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update training loss\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "        \n",
    "    ######################    \n",
    "    # validate the model #\n",
    "    ######################\n",
    "    model.eval()\n",
    "    for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # update average validation loss \n",
    "        valid_loss += loss.item()*data.size(0)\n",
    "    \n",
    "    # calculate average losses\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    valid_loss = valid_loss/len(valid_loader.dataset)\n",
    "        \n",
    "    # print training/validation statistics \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        epoch, train_loss, valid_loss))\n",
    "    \n",
    "    # save model if validation loss has decreased\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        valid_loss_min,\n",
    "        valid_loss))\n",
    "        torch.save(model.state_dict(), 'vangogh_model.pt')\n",
    "        valid_loss_min = valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gd8joQgIrsF8"
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('vangogh_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "keaJo4fAvIIY",
    "outputId": "f643d7ad-1d72-4d23-d9e7-e4b839f054e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.318065\n",
      "\n",
      "Test Accuracy of    vg: 95% (40/42)\n",
      "Test Accuracy of   nvg: 72% (18/25)\n",
      "\n",
      "Test Accuracy (Overall): 86% (58/67)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# track test loss\n",
    "test_loss = 0.0\n",
    "class_correct = list(0. for i in range(1,3))\n",
    "class_total = list(0. for i in range(1,3))\n",
    "\n",
    "model.eval()\n",
    "# iterate over test data\n",
    "for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "    # move tensors to GPU if CUDA is available\n",
    "    if train_on_gpu:\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "    # forward pass: compute predicted outputs by passing inputs to the model\n",
    "    output = model(data)\n",
    "    # calculate the batch loss\n",
    "    loss = criterion(output, target)\n",
    "    # update test loss \n",
    "    test_loss += loss.item()*data.size(0)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, pred = torch.max(output, 1)    \n",
    "    # compare predictions to true label\n",
    "    correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
    "    # calculate test accuracy for each object class\n",
    "    for i in range(len(target.data)):\n",
    "        label = target.data[i]\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] += 1\n",
    "\n",
    "# average test loss\n",
    "test_loss = test_loss/len(valid_loader.dataset)\n",
    "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "for i in range(2):\n",
    "    if class_total[i] > 0:\n",
    "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i],\n",
    "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "    else:\n",
    "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "    100. * np.sum(class_correct) / np.sum(class_total),\n",
    "    np.sum(class_correct), np.sum(class_total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ntW7qLGreQ9e"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# helper function to un-normalize and display an image\n",
    "imshow = transforms.Normalize(\n",
    "    mean=[-0.485/0.229, -0.456/0.224, -0.406/0.255],\n",
    "    std=[1/0.229, 1/0.224, 1/0.255]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "la-71t-SeDVY",
    "outputId": "cf2210bf-d742-44bb-aced-b33f22eba1a1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABYEAAAD2CAYAAACA0EhrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAUNj/AU4MMMxg33CqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd92da4a9b0>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# obtain one batch of test images\n",
    "dataiter = iter(valid_loader)\n",
    "images, labels = dataiter.next()\n",
    "images.numpy()\n",
    "\n",
    "# move model inputs to cuda, if GPU available\n",
    "if train_on_gpu:\n",
    "    images = images.cuda()\n",
    "\n",
    "# get sample outputs\n",
    "output = model(images)\n",
    "# convert output probabilities to predicted class\n",
    "_, preds_tensor = torch.max(output, 1)\n",
    "preds = np.squeeze(preds_tensor.numpy()) if not train_on_gpu else np.squeeze(preds_tensor.cpu().numpy())\n",
    "\n",
    "# plot the images in the batch, along with predicted and true labels\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "for idx in np.arange(20):\n",
    "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
    "    imshow(images[idx])\n",
    "    ax.set_title(\"{} ({})\".format(classes[preds[idx]], classes[labels[idx]]),\n",
    "                 color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "vangogh_categorize_resnet.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
